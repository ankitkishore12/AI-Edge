{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step 1: Import libraries & Set up***"
      ],
      "metadata": {
        "id": "4HVi_V0Yevl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "sequence_length = 28\n",
        "input_size = 12 # N_mffc\n",
        "hidden_size = 64\n",
        "num_layers = 3\n",
        "num_classes = 35\n",
        "batch_size = 1\n",
        "num_epochs = 25\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "AGGTWGcdmAhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step 2: Use trained model (FP32)***\n",
        "Reference: https://github.com/felixchenfy/Speech-Commands-Classification-by-LSTM-PyTorch"
      ],
      "metadata": {
        "id": "rlkk4G0Me87g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recurrent neural network (many-to-one)\n",
        "class LSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        return x\n",
        "model = LSTM(12, 35,64,3)\n",
        "x = torch.randn(batch_size, sequence_length, input_size)\n",
        "out = model(x)\n",
        "print(out)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTci6pxGmCi7",
        "outputId": "b782d64c-ce74-455d-f094-8f717d48b09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.3469, -1.4874, -0.1450, -0.6015,  0.4447, -0.3941, -0.1339,\n",
            "          -1.1706,  0.3192,  0.1349,  0.4416, -0.0699],\n",
            "         [-0.0342, -0.1513,  1.1628,  0.3381, -2.4266,  0.3415,  1.1566,\n",
            "          -1.7085,  0.9702, -0.4843,  1.2344,  0.4435],\n",
            "         [ 1.6728, -1.0947,  1.5710,  1.7005,  0.9928, -0.6565, -2.0365,\n",
            "           0.0337, -0.6766, -0.6277, -0.4878,  0.2219],\n",
            "         [ 0.6002, -0.6824, -0.6465, -0.9033,  1.2781, -0.4886,  0.2029,\n",
            "           1.1325,  0.1463,  1.5354,  1.1932,  0.0048],\n",
            "         [-0.2679, -1.1787, -1.6024,  0.3694, -0.9934,  0.5546, -1.2586,\n",
            "           0.5416, -0.2124,  1.5033, -0.4508, -1.9895],\n",
            "         [ 2.5777,  1.7366, -0.9346,  0.2837, -0.8152, -0.3704,  0.2418,\n",
            "           0.0614, -0.3858,  1.4835, -0.0736,  0.4397],\n",
            "         [-0.9950,  0.6258,  0.1800,  2.7300, -1.5928,  0.2763, -0.1658,\n",
            "          -0.4066,  0.4823, -1.3553,  1.1546,  0.8119],\n",
            "         [ 0.8891,  0.1830,  0.3364,  0.3167, -1.1692,  0.3125, -0.2180,\n",
            "          -0.8463,  0.7863,  0.3406,  0.2392,  0.9701],\n",
            "         [ 1.4230, -0.6458,  0.4166, -0.7994,  0.5097, -0.9592, -0.0097,\n",
            "           1.1307, -0.8086,  1.0554,  0.7487, -0.3199],\n",
            "         [-0.7220, -1.6605, -0.6281, -0.1040, -0.0320,  0.0161, -0.5074,\n",
            "          -0.8137,  1.9097,  0.4306, -0.1954,  0.3026],\n",
            "         [-2.1524,  0.5467, -0.5770, -0.3436, -0.2901,  0.3612,  0.2687,\n",
            "           0.4907,  0.1969,  0.1361, -1.1692, -0.3698],\n",
            "         [ 1.3321,  1.4545,  1.2042, -0.7518,  1.1944, -0.1205,  1.7312,\n",
            "           0.9546,  0.9656, -0.1626, -0.7714, -1.0717],\n",
            "         [-1.0636, -1.5432,  0.8644,  0.7235,  1.0843,  0.6996,  0.3332,\n",
            "           0.4722,  0.8526,  1.6692, -0.5927,  0.2859],\n",
            "         [ 1.8412, -0.8743, -0.6029,  0.6285, -0.0621,  1.4313, -1.3213,\n",
            "          -1.2306,  2.3802, -0.1214,  0.2421, -0.7743],\n",
            "         [ 0.1155, -0.8496, -1.7750, -0.5082,  1.1946,  0.8673, -0.8693,\n",
            "          -0.3611, -1.2316, -1.5568, -0.2930,  0.5536],\n",
            "         [-1.2386, -1.6667,  1.3667,  0.0583,  0.5698, -1.3776,  0.0257,\n",
            "          -1.7289, -0.6157,  1.1598, -0.1258, -0.0340],\n",
            "         [ 0.5071, -0.2069, -1.0178, -0.3001, -0.2758, -0.2636,  0.4997,\n",
            "           0.9406,  1.9254,  1.0414, -0.7788, -1.6231],\n",
            "         [ 0.4270,  0.6019, -0.2001,  1.4181, -1.0158, -1.3206, -0.4946,\n",
            "          -0.0628,  0.8524, -0.4882,  1.5627, -0.8923],\n",
            "         [ 0.0709, -0.8275, -1.3215, -2.3887,  1.1954,  0.5870,  1.9099,\n",
            "          -1.2061,  0.5862,  0.2738,  0.1187,  0.2341],\n",
            "         [-0.0572, -0.4580, -0.5840,  1.0584,  1.0001,  0.9362, -0.2172,\n",
            "          -0.3270, -0.2019,  0.1120, -0.1408,  1.1485],\n",
            "         [-0.7865,  1.7298,  0.7637,  0.5961,  0.5916,  1.5370,  2.1159,\n",
            "           0.3139,  1.3594, -0.5067,  0.5330, -0.2075],\n",
            "         [-0.1657, -1.5589,  1.6479,  0.4924,  0.4002,  1.5047,  0.5935,\n",
            "           0.5697, -0.5619, -2.7332, -2.3000,  0.4230],\n",
            "         [ 0.7149, -0.5318,  1.2286,  0.4143,  0.2029, -0.2543, -1.7977,\n",
            "          -0.3891, -0.6786, -0.7187, -1.4711,  0.3230],\n",
            "         [-1.9703,  0.7629, -0.6664,  0.0373,  0.0803,  0.9308,  0.9721,\n",
            "          -0.1900,  0.2211,  1.0069, -3.3744, -2.4978],\n",
            "         [-2.1158, -0.9298, -1.8771, -0.2056,  0.0416, -0.2588, -0.4285,\n",
            "          -0.2747, -0.8066, -0.5296, -0.9084, -1.4104],\n",
            "         [ 0.5844, -0.8491,  0.0968, -1.2683,  0.7822,  1.6793, -0.2503,\n",
            "          -1.4374,  0.3037, -1.7415,  0.1203,  1.8653],\n",
            "         [-0.5816,  1.9501,  0.4225,  1.5358,  0.3444, -0.4358,  0.1380,\n",
            "          -1.5701,  0.0470, -0.8974, -0.7152,  0.8165],\n",
            "         [ 0.6292,  0.3924, -0.9036,  0.1251, -1.0292,  0.8971, -0.5241,\n",
            "          -0.9295, -0.9907, -0.0436, -1.0118,  0.7232]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***--- Above LSTM model tensors representation for Affine per tensor quantization--***"
      ],
      "metadata": {
        "id": "aqK0mQh01n40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "aJErx-Ug2o_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = torch.tensor(out)\n",
        "print(T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S27-QwZTKsEg",
        "outputId": "9d16931d-fcb6-406d-ee57-6e1fc959f7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.3469, -1.4874, -0.1450, -0.6015,  0.4447, -0.3941, -0.1339,\n",
            "          -1.1706,  0.3192,  0.1349,  0.4416, -0.0699],\n",
            "         [-0.0342, -0.1513,  1.1628,  0.3381, -2.4266,  0.3415,  1.1566,\n",
            "          -1.7085,  0.9702, -0.4843,  1.2344,  0.4435],\n",
            "         [ 1.6728, -1.0947,  1.5710,  1.7005,  0.9928, -0.6565, -2.0365,\n",
            "           0.0337, -0.6766, -0.6277, -0.4878,  0.2219],\n",
            "         [ 0.6002, -0.6824, -0.6465, -0.9033,  1.2781, -0.4886,  0.2029,\n",
            "           1.1325,  0.1463,  1.5354,  1.1932,  0.0048],\n",
            "         [-0.2679, -1.1787, -1.6024,  0.3694, -0.9934,  0.5546, -1.2586,\n",
            "           0.5416, -0.2124,  1.5033, -0.4508, -1.9895],\n",
            "         [ 2.5777,  1.7366, -0.9346,  0.2837, -0.8152, -0.3704,  0.2418,\n",
            "           0.0614, -0.3858,  1.4835, -0.0736,  0.4397],\n",
            "         [-0.9950,  0.6258,  0.1800,  2.7300, -1.5928,  0.2763, -0.1658,\n",
            "          -0.4066,  0.4823, -1.3553,  1.1546,  0.8119],\n",
            "         [ 0.8891,  0.1830,  0.3364,  0.3167, -1.1692,  0.3125, -0.2180,\n",
            "          -0.8463,  0.7863,  0.3406,  0.2392,  0.9701],\n",
            "         [ 1.4230, -0.6458,  0.4166, -0.7994,  0.5097, -0.9592, -0.0097,\n",
            "           1.1307, -0.8086,  1.0554,  0.7487, -0.3199],\n",
            "         [-0.7220, -1.6605, -0.6281, -0.1040, -0.0320,  0.0161, -0.5074,\n",
            "          -0.8137,  1.9097,  0.4306, -0.1954,  0.3026],\n",
            "         [-2.1524,  0.5467, -0.5770, -0.3436, -0.2901,  0.3612,  0.2687,\n",
            "           0.4907,  0.1969,  0.1361, -1.1692, -0.3698],\n",
            "         [ 1.3321,  1.4545,  1.2042, -0.7518,  1.1944, -0.1205,  1.7312,\n",
            "           0.9546,  0.9656, -0.1626, -0.7714, -1.0717],\n",
            "         [-1.0636, -1.5432,  0.8644,  0.7235,  1.0843,  0.6996,  0.3332,\n",
            "           0.4722,  0.8526,  1.6692, -0.5927,  0.2859],\n",
            "         [ 1.8412, -0.8743, -0.6029,  0.6285, -0.0621,  1.4313, -1.3213,\n",
            "          -1.2306,  2.3802, -0.1214,  0.2421, -0.7743],\n",
            "         [ 0.1155, -0.8496, -1.7750, -0.5082,  1.1946,  0.8673, -0.8693,\n",
            "          -0.3611, -1.2316, -1.5568, -0.2930,  0.5536],\n",
            "         [-1.2386, -1.6667,  1.3667,  0.0583,  0.5698, -1.3776,  0.0257,\n",
            "          -1.7289, -0.6157,  1.1598, -0.1258, -0.0340],\n",
            "         [ 0.5071, -0.2069, -1.0178, -0.3001, -0.2758, -0.2636,  0.4997,\n",
            "           0.9406,  1.9254,  1.0414, -0.7788, -1.6231],\n",
            "         [ 0.4270,  0.6019, -0.2001,  1.4181, -1.0158, -1.3206, -0.4946,\n",
            "          -0.0628,  0.8524, -0.4882,  1.5627, -0.8923],\n",
            "         [ 0.0709, -0.8275, -1.3215, -2.3887,  1.1954,  0.5870,  1.9099,\n",
            "          -1.2061,  0.5862,  0.2738,  0.1187,  0.2341],\n",
            "         [-0.0572, -0.4580, -0.5840,  1.0584,  1.0001,  0.9362, -0.2172,\n",
            "          -0.3270, -0.2019,  0.1120, -0.1408,  1.1485],\n",
            "         [-0.7865,  1.7298,  0.7637,  0.5961,  0.5916,  1.5370,  2.1159,\n",
            "           0.3139,  1.3594, -0.5067,  0.5330, -0.2075],\n",
            "         [-0.1657, -1.5589,  1.6479,  0.4924,  0.4002,  1.5047,  0.5935,\n",
            "           0.5697, -0.5619, -2.7332, -2.3000,  0.4230],\n",
            "         [ 0.7149, -0.5318,  1.2286,  0.4143,  0.2029, -0.2543, -1.7977,\n",
            "          -0.3891, -0.6786, -0.7187, -1.4711,  0.3230],\n",
            "         [-1.9703,  0.7629, -0.6664,  0.0373,  0.0803,  0.9308,  0.9721,\n",
            "          -0.1900,  0.2211,  1.0069, -3.3744, -2.4978],\n",
            "         [-2.1158, -0.9298, -1.8771, -0.2056,  0.0416, -0.2588, -0.4285,\n",
            "          -0.2747, -0.8066, -0.5296, -0.9084, -1.4104],\n",
            "         [ 0.5844, -0.8491,  0.0968, -1.2683,  0.7822,  1.6793, -0.2503,\n",
            "          -1.4374,  0.3037, -1.7415,  0.1203,  1.8653],\n",
            "         [-0.5816,  1.9501,  0.4225,  1.5358,  0.3444, -0.4358,  0.1380,\n",
            "          -1.5701,  0.0470, -0.8974, -0.7152,  0.8165],\n",
            "         [ 0.6292,  0.3924, -0.9036,  0.1251, -1.0292,  0.8971, -0.5241,\n",
            "          -0.9295, -0.9907, -0.0436, -1.0118,  0.7232]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***--Maximum Value and minimum value of x***"
      ],
      "metadata": {
        "id": "d5KsODlj1I-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-Max value of float_32 tensor (x) find out for scale (s) and zero point (z)\n",
        "\n",
        "b = torch.max(T)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "KqJfmzPyKLJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c4668a-38d4-4ed1-da89-83a0f4a179d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.7300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.min(T)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "6T8gFLidK-6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a36fb0-2425-4226-cf8f-d9d578408cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-3.3744)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale value\n",
        "\n",
        "s = (b-a)/255\n",
        "\n",
        "print(s)"
      ],
      "metadata": {
        "id": "LEfqrb4RVg4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86355ec2-a348-4be8-e456-14bbcff7b13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0239)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zero point\n",
        "\n",
        "z = torch.round(-a*255/(b-a))\n",
        "\n",
        "print(z)"
      ],
      "metadata": {
        "id": "LK8rTzkkV0pK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408e00e5-a9f8-484c-f70d-3ead52861815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(141.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step-3: Apply Quantization by round and clipping function (Affine mapping)***"
      ],
      "metadata": {
        "id": "pLhbVDUf1X2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = torch.round(T/s + z)\n",
        "print(f)\n",
        "Tq = torch.clip(f, min=0, max=255) # Here min & max value we can change as per Tbit.\n",
        "# But, I have checked for 8 bit\n",
        "print (Tq)\n",
        "torch.save(Tq,'qtz_tensor.pt')\n"
      ],
      "metadata": {
        "id": "wWHlM_8OxrDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aca9c6d-5fca-4e45-808a-23ed13e104b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[155.,  79., 135., 116., 160., 125., 135.,  92., 154., 147., 159.,\n",
            "          138.],\n",
            "         [140., 135., 190., 155.,  40., 155., 189.,  70., 182., 121., 193.,\n",
            "          160.],\n",
            "         [211.,  95., 207., 212., 182., 114.,  56., 142., 113., 115., 121.,\n",
            "          150.],\n",
            "         [166., 112., 114., 103., 194., 121., 149., 188., 147., 205., 191.,\n",
            "          141.],\n",
            "         [130.,  92.,  74., 156., 100., 164.,  88., 164., 132., 204., 122.,\n",
            "           58.],\n",
            "         [249., 214., 102., 153., 107., 126., 151., 144., 125., 203., 138.,\n",
            "          159.],\n",
            "         [ 99., 167., 149., 255.,  74., 153., 134., 124., 161.,  84., 189.,\n",
            "          175.],\n",
            "         [178., 149., 155., 154.,  92., 154., 132., 106., 174., 155., 151.,\n",
            "          182.],\n",
            "         [200., 114., 158., 108., 162., 101., 141., 188., 107., 185., 172.,\n",
            "          128.],\n",
            "         [111.,  72., 115., 137., 140., 142., 120., 107., 221., 159., 133.,\n",
            "          154.],\n",
            "         [ 51., 164., 117., 127., 129., 156., 152., 161., 149., 147.,  92.,\n",
            "          126.],\n",
            "         [197., 202., 191., 110., 191., 136., 213., 181., 181., 134., 109.,\n",
            "           96.],\n",
            "         [ 97.,  77., 177., 171., 186., 170., 155., 161., 177., 211., 116.,\n",
            "          153.],\n",
            "         [218., 104., 116., 167., 138., 201.,  86.,  90., 240., 136., 151.,\n",
            "          109.],\n",
            "         [146., 106.,  67., 120., 191., 177., 105., 126.,  90.,  76., 129.,\n",
            "          164.],\n",
            "         [ 89.,  71., 198., 143., 165.,  83., 142.,  69., 115., 189., 136.,\n",
            "          140.],\n",
            "         [162., 132.,  98., 128., 129., 130., 162., 180., 221., 185., 108.,\n",
            "           73.],\n",
            "         [159., 166., 133., 200.,  99.,  86., 120., 138., 177., 121., 206.,\n",
            "          104.],\n",
            "         [144., 106.,  86.,  41., 191., 166., 221.,  91., 165., 152., 146.,\n",
            "          151.],\n",
            "         [139., 122., 117., 185., 183., 180., 132., 127., 133., 146., 135.,\n",
            "          189.],\n",
            "         [108., 213., 173., 166., 166., 205., 229., 154., 198., 120., 163.,\n",
            "          132.],\n",
            "         [134.,  76., 210., 162., 158., 204., 166., 165., 118.,  27.,  45.,\n",
            "          159.],\n",
            "         [171., 119., 192., 158., 149., 130.,  66., 125., 113., 111.,  80.,\n",
            "          154.],\n",
            "         [ 59., 173., 113., 143., 144., 180., 182., 133., 150., 183.,   0.,\n",
            "           37.],\n",
            "         [ 53., 102.,  63., 132., 143., 130., 123., 130., 107., 119., 103.,\n",
            "           82.],\n",
            "         [165., 106., 145.,  88., 174., 211., 131.,  81., 154.,  68., 146.,\n",
            "          219.],\n",
            "         [117., 222., 159., 205., 155., 123., 147.,  75., 143., 104., 111.,\n",
            "          175.],\n",
            "         [167., 157., 103., 146.,  98., 178., 119., 102., 100., 139.,  99.,\n",
            "          171.]]])\n",
            "tensor([[[155.,  79., 135., 116., 160., 125., 135.,  92., 154., 147., 159.,\n",
            "          138.],\n",
            "         [140., 135., 190., 155.,  40., 155., 189.,  70., 182., 121., 193.,\n",
            "          160.],\n",
            "         [211.,  95., 207., 212., 182., 114.,  56., 142., 113., 115., 121.,\n",
            "          150.],\n",
            "         [166., 112., 114., 103., 194., 121., 149., 188., 147., 205., 191.,\n",
            "          141.],\n",
            "         [130.,  92.,  74., 156., 100., 164.,  88., 164., 132., 204., 122.,\n",
            "           58.],\n",
            "         [249., 214., 102., 153., 107., 126., 151., 144., 125., 203., 138.,\n",
            "          159.],\n",
            "         [ 99., 167., 149., 255.,  74., 153., 134., 124., 161.,  84., 189.,\n",
            "          175.],\n",
            "         [178., 149., 155., 154.,  92., 154., 132., 106., 174., 155., 151.,\n",
            "          182.],\n",
            "         [200., 114., 158., 108., 162., 101., 141., 188., 107., 185., 172.,\n",
            "          128.],\n",
            "         [111.,  72., 115., 137., 140., 142., 120., 107., 221., 159., 133.,\n",
            "          154.],\n",
            "         [ 51., 164., 117., 127., 129., 156., 152., 161., 149., 147.,  92.,\n",
            "          126.],\n",
            "         [197., 202., 191., 110., 191., 136., 213., 181., 181., 134., 109.,\n",
            "           96.],\n",
            "         [ 97.,  77., 177., 171., 186., 170., 155., 161., 177., 211., 116.,\n",
            "          153.],\n",
            "         [218., 104., 116., 167., 138., 201.,  86.,  90., 240., 136., 151.,\n",
            "          109.],\n",
            "         [146., 106.,  67., 120., 191., 177., 105., 126.,  90.,  76., 129.,\n",
            "          164.],\n",
            "         [ 89.,  71., 198., 143., 165.,  83., 142.,  69., 115., 189., 136.,\n",
            "          140.],\n",
            "         [162., 132.,  98., 128., 129., 130., 162., 180., 221., 185., 108.,\n",
            "           73.],\n",
            "         [159., 166., 133., 200.,  99.,  86., 120., 138., 177., 121., 206.,\n",
            "          104.],\n",
            "         [144., 106.,  86.,  41., 191., 166., 221.,  91., 165., 152., 146.,\n",
            "          151.],\n",
            "         [139., 122., 117., 185., 183., 180., 132., 127., 133., 146., 135.,\n",
            "          189.],\n",
            "         [108., 213., 173., 166., 166., 205., 229., 154., 198., 120., 163.,\n",
            "          132.],\n",
            "         [134.,  76., 210., 162., 158., 204., 166., 165., 118.,  27.,  45.,\n",
            "          159.],\n",
            "         [171., 119., 192., 158., 149., 130.,  66., 125., 113., 111.,  80.,\n",
            "          154.],\n",
            "         [ 59., 173., 113., 143., 144., 180., 182., 133., 150., 183.,   0.,\n",
            "           37.],\n",
            "         [ 53., 102.,  63., 132., 143., 130., 123., 130., 107., 119., 103.,\n",
            "           82.],\n",
            "         [165., 106., 145.,  88., 174., 211., 131.,  81., 154.,  68., 146.,\n",
            "          219.],\n",
            "         [117., 222., 159., 205., 155., 123., 147.,  75., 143., 104., 111.,\n",
            "          175.],\n",
            "         [167., 157., 103., 146.,  98., 178., 119., 102., 100., 139.,  99.,\n",
            "          171.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step-4: Apply Dequantization***"
      ],
      "metadata": {
        "id": "8DezhWFY1gS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tdq = s*(Tq - z)\n",
        "print(Tdq)"
      ],
      "metadata": {
        "id": "mkBcnWa29WyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8e390a-0517-4dab-9924-d25159f969f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.3351, -1.4842, -0.1436, -0.5985,  0.4548, -0.3830, -0.1436,\n",
            "          -1.1730,  0.3112,  0.1436,  0.4309, -0.0718],\n",
            "         [-0.0239, -0.1436,  1.1730,  0.3351, -2.4178,  0.3351,  1.1491,\n",
            "          -1.6997,  0.9815, -0.4788,  1.2448,  0.4548],\n",
            "         [ 1.6757, -1.1012,  1.5800,  1.6997,  0.9815, -0.6464, -2.0348,\n",
            "           0.0239, -0.6703, -0.6224, -0.4788,  0.2155],\n",
            "         [ 0.5985, -0.6942, -0.6464, -0.9097,  1.2688, -0.4788,  0.1915,\n",
            "           1.1251,  0.1436,  1.5321,  1.1969,  0.0000],\n",
            "         [-0.2633, -1.1730, -1.6039,  0.3591, -0.9815,  0.5506, -1.2688,\n",
            "           0.5506, -0.2155,  1.5082, -0.4548, -1.9869],\n",
            "         [ 2.5854,  1.7475, -0.9336,  0.2873, -0.8139, -0.3591,  0.2394,\n",
            "           0.0718, -0.3830,  1.4842, -0.0718,  0.4309],\n",
            "         [-1.0054,  0.6224,  0.1915,  2.7290, -1.6039,  0.2873, -0.1676,\n",
            "          -0.4070,  0.4788, -1.3645,  1.1491,  0.8139],\n",
            "         [ 0.8857,  0.1915,  0.3351,  0.3112, -1.1730,  0.3112, -0.2155,\n",
            "          -0.8379,  0.7900,  0.3351,  0.2394,  0.9815],\n",
            "         [ 1.4124, -0.6464,  0.4070, -0.7900,  0.5027, -0.9576,  0.0000,\n",
            "           1.1251, -0.8139,  1.0533,  0.7421, -0.3112],\n",
            "         [-0.7182, -1.6518, -0.6224, -0.0958, -0.0239,  0.0239, -0.5027,\n",
            "          -0.8139,  1.9151,  0.4309, -0.1915,  0.3112],\n",
            "         [-2.1545,  0.5506, -0.5745, -0.3351, -0.2873,  0.3591,  0.2633,\n",
            "           0.4788,  0.1915,  0.1436, -1.1730, -0.3591],\n",
            "         [ 1.3406,  1.4603,  1.1969, -0.7421,  1.1969, -0.1197,  1.7236,\n",
            "           0.9576,  0.9576, -0.1676, -0.7660, -1.0773],\n",
            "         [-1.0533, -1.5321,  0.8618,  0.7182,  1.0773,  0.6942,  0.3351,\n",
            "           0.4788,  0.8618,  1.6757, -0.5985,  0.2873],\n",
            "         [ 1.8433, -0.8857, -0.5985,  0.6224, -0.0718,  1.4363, -1.3166,\n",
            "          -1.2209,  2.3700, -0.1197,  0.2394, -0.7660],\n",
            "         [ 0.1197, -0.8379, -1.7715, -0.5027,  1.1969,  0.8618, -0.8618,\n",
            "          -0.3591, -1.2209, -1.5560, -0.2873,  0.5506],\n",
            "         [-1.2448, -1.6757,  1.3645,  0.0479,  0.5745, -1.3885,  0.0239,\n",
            "          -1.7236, -0.6224,  1.1491, -0.1197, -0.0239],\n",
            "         [ 0.5027, -0.2155, -1.0294, -0.3112, -0.2873, -0.2633,  0.5027,\n",
            "           0.9336,  1.9151,  1.0533, -0.7900, -1.6279],\n",
            "         [ 0.4309,  0.5985, -0.1915,  1.4124, -1.0054, -1.3166, -0.5027,\n",
            "          -0.0718,  0.8618, -0.4788,  1.5560, -0.8857],\n",
            "         [ 0.0718, -0.8379, -1.3166, -2.3939,  1.1969,  0.5985,  1.9151,\n",
            "          -1.1969,  0.5745,  0.2633,  0.1197,  0.2394],\n",
            "         [-0.0479, -0.4548, -0.5745,  1.0533,  1.0054,  0.9336, -0.2155,\n",
            "          -0.3351, -0.1915,  0.1197, -0.1436,  1.1491],\n",
            "         [-0.7900,  1.7236,  0.7660,  0.5985,  0.5985,  1.5321,  2.1066,\n",
            "           0.3112,  1.3645, -0.5027,  0.5267, -0.2155],\n",
            "         [-0.1676, -1.5560,  1.6518,  0.5027,  0.4070,  1.5082,  0.5985,\n",
            "           0.5745, -0.5506, -2.7290, -2.2981,  0.4309],\n",
            "         [ 0.7182, -0.5267,  1.2209,  0.4070,  0.1915, -0.2633, -1.7954,\n",
            "          -0.3830, -0.6703, -0.7182, -1.4603,  0.3112],\n",
            "         [-1.9630,  0.7660, -0.6703,  0.0479,  0.0718,  0.9336,  0.9815,\n",
            "          -0.1915,  0.2155,  1.0054, -3.3754, -2.4897],\n",
            "         [-2.1066, -0.9336, -1.8672, -0.2155,  0.0479, -0.2633, -0.4309,\n",
            "          -0.2633, -0.8139, -0.5267, -0.9097, -1.4124],\n",
            "         [ 0.5745, -0.8379,  0.0958, -1.2688,  0.7900,  1.6757, -0.2394,\n",
            "          -1.4363,  0.3112, -1.7475,  0.1197,  1.8672],\n",
            "         [-0.5745,  1.9391,  0.4309,  1.5321,  0.3351, -0.4309,  0.1436,\n",
            "          -1.5800,  0.0479, -0.8857, -0.7182,  0.8139],\n",
            "         [ 0.6224,  0.3830, -0.9097,  0.1197, -1.0294,  0.8857, -0.5267,\n",
            "          -0.9336, -0.9815, -0.0479, -1.0054,  0.7182]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step-5: MAE/MSE loss between T and Tdq***"
      ],
      "metadata": {
        "id": "q2_h6bwY11V1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I. MAE loss***"
      ],
      "metadata": {
        "id": "kwfk5ErP16k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# print input and target tensors\n",
        "print(\"Input Tensor:\\n\", T)\n",
        "print(\"Target Tensor:\\n\", Tdq)\n",
        "# create a criterion to measure the mean absolute error\n",
        "mae = nn.L1Loss()\n",
        "# compute the loss (mean absolute error)\n",
        "output = mae(T, Tdq)\n",
        "# output.backward()\n",
        "print(\"MAE loss:\", output)"
      ],
      "metadata": {
        "id": "V3OJ-UTVRGL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d37487d-860c-4b6a-b457-b00a598d3c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor:\n",
            " tensor([[[ 0.3469, -1.4874, -0.1450, -0.6015,  0.4447, -0.3941, -0.1339,\n",
            "          -1.1706,  0.3192,  0.1349,  0.4416, -0.0699],\n",
            "         [-0.0342, -0.1513,  1.1628,  0.3381, -2.4266,  0.3415,  1.1566,\n",
            "          -1.7085,  0.9702, -0.4843,  1.2344,  0.4435],\n",
            "         [ 1.6728, -1.0947,  1.5710,  1.7005,  0.9928, -0.6565, -2.0365,\n",
            "           0.0337, -0.6766, -0.6277, -0.4878,  0.2219],\n",
            "         [ 0.6002, -0.6824, -0.6465, -0.9033,  1.2781, -0.4886,  0.2029,\n",
            "           1.1325,  0.1463,  1.5354,  1.1932,  0.0048],\n",
            "         [-0.2679, -1.1787, -1.6024,  0.3694, -0.9934,  0.5546, -1.2586,\n",
            "           0.5416, -0.2124,  1.5033, -0.4508, -1.9895],\n",
            "         [ 2.5777,  1.7366, -0.9346,  0.2837, -0.8152, -0.3704,  0.2418,\n",
            "           0.0614, -0.3858,  1.4835, -0.0736,  0.4397],\n",
            "         [-0.9950,  0.6258,  0.1800,  2.7300, -1.5928,  0.2763, -0.1658,\n",
            "          -0.4066,  0.4823, -1.3553,  1.1546,  0.8119],\n",
            "         [ 0.8891,  0.1830,  0.3364,  0.3167, -1.1692,  0.3125, -0.2180,\n",
            "          -0.8463,  0.7863,  0.3406,  0.2392,  0.9701],\n",
            "         [ 1.4230, -0.6458,  0.4166, -0.7994,  0.5097, -0.9592, -0.0097,\n",
            "           1.1307, -0.8086,  1.0554,  0.7487, -0.3199],\n",
            "         [-0.7220, -1.6605, -0.6281, -0.1040, -0.0320,  0.0161, -0.5074,\n",
            "          -0.8137,  1.9097,  0.4306, -0.1954,  0.3026],\n",
            "         [-2.1524,  0.5467, -0.5770, -0.3436, -0.2901,  0.3612,  0.2687,\n",
            "           0.4907,  0.1969,  0.1361, -1.1692, -0.3698],\n",
            "         [ 1.3321,  1.4545,  1.2042, -0.7518,  1.1944, -0.1205,  1.7312,\n",
            "           0.9546,  0.9656, -0.1626, -0.7714, -1.0717],\n",
            "         [-1.0636, -1.5432,  0.8644,  0.7235,  1.0843,  0.6996,  0.3332,\n",
            "           0.4722,  0.8526,  1.6692, -0.5927,  0.2859],\n",
            "         [ 1.8412, -0.8743, -0.6029,  0.6285, -0.0621,  1.4313, -1.3213,\n",
            "          -1.2306,  2.3802, -0.1214,  0.2421, -0.7743],\n",
            "         [ 0.1155, -0.8496, -1.7750, -0.5082,  1.1946,  0.8673, -0.8693,\n",
            "          -0.3611, -1.2316, -1.5568, -0.2930,  0.5536],\n",
            "         [-1.2386, -1.6667,  1.3667,  0.0583,  0.5698, -1.3776,  0.0257,\n",
            "          -1.7289, -0.6157,  1.1598, -0.1258, -0.0340],\n",
            "         [ 0.5071, -0.2069, -1.0178, -0.3001, -0.2758, -0.2636,  0.4997,\n",
            "           0.9406,  1.9254,  1.0414, -0.7788, -1.6231],\n",
            "         [ 0.4270,  0.6019, -0.2001,  1.4181, -1.0158, -1.3206, -0.4946,\n",
            "          -0.0628,  0.8524, -0.4882,  1.5627, -0.8923],\n",
            "         [ 0.0709, -0.8275, -1.3215, -2.3887,  1.1954,  0.5870,  1.9099,\n",
            "          -1.2061,  0.5862,  0.2738,  0.1187,  0.2341],\n",
            "         [-0.0572, -0.4580, -0.5840,  1.0584,  1.0001,  0.9362, -0.2172,\n",
            "          -0.3270, -0.2019,  0.1120, -0.1408,  1.1485],\n",
            "         [-0.7865,  1.7298,  0.7637,  0.5961,  0.5916,  1.5370,  2.1159,\n",
            "           0.3139,  1.3594, -0.5067,  0.5330, -0.2075],\n",
            "         [-0.1657, -1.5589,  1.6479,  0.4924,  0.4002,  1.5047,  0.5935,\n",
            "           0.5697, -0.5619, -2.7332, -2.3000,  0.4230],\n",
            "         [ 0.7149, -0.5318,  1.2286,  0.4143,  0.2029, -0.2543, -1.7977,\n",
            "          -0.3891, -0.6786, -0.7187, -1.4711,  0.3230],\n",
            "         [-1.9703,  0.7629, -0.6664,  0.0373,  0.0803,  0.9308,  0.9721,\n",
            "          -0.1900,  0.2211,  1.0069, -3.3744, -2.4978],\n",
            "         [-2.1158, -0.9298, -1.8771, -0.2056,  0.0416, -0.2588, -0.4285,\n",
            "          -0.2747, -0.8066, -0.5296, -0.9084, -1.4104],\n",
            "         [ 0.5844, -0.8491,  0.0968, -1.2683,  0.7822,  1.6793, -0.2503,\n",
            "          -1.4374,  0.3037, -1.7415,  0.1203,  1.8653],\n",
            "         [-0.5816,  1.9501,  0.4225,  1.5358,  0.3444, -0.4358,  0.1380,\n",
            "          -1.5701,  0.0470, -0.8974, -0.7152,  0.8165],\n",
            "         [ 0.6292,  0.3924, -0.9036,  0.1251, -1.0292,  0.8971, -0.5241,\n",
            "          -0.9295, -0.9907, -0.0436, -1.0118,  0.7232]]])\n",
            "Target Tensor:\n",
            " tensor([[[ 0.3351, -1.4842, -0.1436, -0.5985,  0.4548, -0.3830, -0.1436,\n",
            "          -1.1730,  0.3112,  0.1436,  0.4309, -0.0718],\n",
            "         [-0.0239, -0.1436,  1.1730,  0.3351, -2.4178,  0.3351,  1.1491,\n",
            "          -1.6997,  0.9815, -0.4788,  1.2448,  0.4548],\n",
            "         [ 1.6757, -1.1012,  1.5800,  1.6997,  0.9815, -0.6464, -2.0348,\n",
            "           0.0239, -0.6703, -0.6224, -0.4788,  0.2155],\n",
            "         [ 0.5985, -0.6942, -0.6464, -0.9097,  1.2688, -0.4788,  0.1915,\n",
            "           1.1251,  0.1436,  1.5321,  1.1969,  0.0000],\n",
            "         [-0.2633, -1.1730, -1.6039,  0.3591, -0.9815,  0.5506, -1.2688,\n",
            "           0.5506, -0.2155,  1.5082, -0.4548, -1.9869],\n",
            "         [ 2.5854,  1.7475, -0.9336,  0.2873, -0.8139, -0.3591,  0.2394,\n",
            "           0.0718, -0.3830,  1.4842, -0.0718,  0.4309],\n",
            "         [-1.0054,  0.6224,  0.1915,  2.7290, -1.6039,  0.2873, -0.1676,\n",
            "          -0.4070,  0.4788, -1.3645,  1.1491,  0.8139],\n",
            "         [ 0.8857,  0.1915,  0.3351,  0.3112, -1.1730,  0.3112, -0.2155,\n",
            "          -0.8379,  0.7900,  0.3351,  0.2394,  0.9815],\n",
            "         [ 1.4124, -0.6464,  0.4070, -0.7900,  0.5027, -0.9576,  0.0000,\n",
            "           1.1251, -0.8139,  1.0533,  0.7421, -0.3112],\n",
            "         [-0.7182, -1.6518, -0.6224, -0.0958, -0.0239,  0.0239, -0.5027,\n",
            "          -0.8139,  1.9151,  0.4309, -0.1915,  0.3112],\n",
            "         [-2.1545,  0.5506, -0.5745, -0.3351, -0.2873,  0.3591,  0.2633,\n",
            "           0.4788,  0.1915,  0.1436, -1.1730, -0.3591],\n",
            "         [ 1.3406,  1.4603,  1.1969, -0.7421,  1.1969, -0.1197,  1.7236,\n",
            "           0.9576,  0.9576, -0.1676, -0.7660, -1.0773],\n",
            "         [-1.0533, -1.5321,  0.8618,  0.7182,  1.0773,  0.6942,  0.3351,\n",
            "           0.4788,  0.8618,  1.6757, -0.5985,  0.2873],\n",
            "         [ 1.8433, -0.8857, -0.5985,  0.6224, -0.0718,  1.4363, -1.3166,\n",
            "          -1.2209,  2.3700, -0.1197,  0.2394, -0.7660],\n",
            "         [ 0.1197, -0.8379, -1.7715, -0.5027,  1.1969,  0.8618, -0.8618,\n",
            "          -0.3591, -1.2209, -1.5560, -0.2873,  0.5506],\n",
            "         [-1.2448, -1.6757,  1.3645,  0.0479,  0.5745, -1.3885,  0.0239,\n",
            "          -1.7236, -0.6224,  1.1491, -0.1197, -0.0239],\n",
            "         [ 0.5027, -0.2155, -1.0294, -0.3112, -0.2873, -0.2633,  0.5027,\n",
            "           0.9336,  1.9151,  1.0533, -0.7900, -1.6279],\n",
            "         [ 0.4309,  0.5985, -0.1915,  1.4124, -1.0054, -1.3166, -0.5027,\n",
            "          -0.0718,  0.8618, -0.4788,  1.5560, -0.8857],\n",
            "         [ 0.0718, -0.8379, -1.3166, -2.3939,  1.1969,  0.5985,  1.9151,\n",
            "          -1.1969,  0.5745,  0.2633,  0.1197,  0.2394],\n",
            "         [-0.0479, -0.4548, -0.5745,  1.0533,  1.0054,  0.9336, -0.2155,\n",
            "          -0.3351, -0.1915,  0.1197, -0.1436,  1.1491],\n",
            "         [-0.7900,  1.7236,  0.7660,  0.5985,  0.5985,  1.5321,  2.1066,\n",
            "           0.3112,  1.3645, -0.5027,  0.5267, -0.2155],\n",
            "         [-0.1676, -1.5560,  1.6518,  0.5027,  0.4070,  1.5082,  0.5985,\n",
            "           0.5745, -0.5506, -2.7290, -2.2981,  0.4309],\n",
            "         [ 0.7182, -0.5267,  1.2209,  0.4070,  0.1915, -0.2633, -1.7954,\n",
            "          -0.3830, -0.6703, -0.7182, -1.4603,  0.3112],\n",
            "         [-1.9630,  0.7660, -0.6703,  0.0479,  0.0718,  0.9336,  0.9815,\n",
            "          -0.1915,  0.2155,  1.0054, -3.3754, -2.4897],\n",
            "         [-2.1066, -0.9336, -1.8672, -0.2155,  0.0479, -0.2633, -0.4309,\n",
            "          -0.2633, -0.8139, -0.5267, -0.9097, -1.4124],\n",
            "         [ 0.5745, -0.8379,  0.0958, -1.2688,  0.7900,  1.6757, -0.2394,\n",
            "          -1.4363,  0.3112, -1.7475,  0.1197,  1.8672],\n",
            "         [-0.5745,  1.9391,  0.4309,  1.5321,  0.3351, -0.4309,  0.1436,\n",
            "          -1.5800,  0.0479, -0.8857, -0.7182,  0.8139],\n",
            "         [ 0.6224,  0.3830, -0.9097,  0.1197, -1.0294,  0.8857, -0.5267,\n",
            "          -0.9336, -0.9815, -0.0479, -1.0054,  0.7182]]])\n",
            "MAE loss: tensor(0.0061)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***II. MSE Loss***"
      ],
      "metadata": {
        "id": "3DtNVxtj2Aa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# print input and target tensors\n",
        "print(\"Input Tensor:\\n\", T)\n",
        "print(\"Target Tensor:\\n\", Tdq)\n",
        "\n",
        "# create a criterion to measure the mean squared error\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "# compute the loss (mean squared error)\n",
        "output = mse(T, Tdq)\n",
        "\n",
        "# output.backward()\n",
        "print(\"MSE loss:\", output)"
      ],
      "metadata": {
        "id": "_eHiK3LN6rsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea261bfc-d46a-4cfa-92df-a4100d2b760b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor:\n",
            " tensor([[[ 0.3469, -1.4874, -0.1450, -0.6015,  0.4447, -0.3941, -0.1339,\n",
            "          -1.1706,  0.3192,  0.1349,  0.4416, -0.0699],\n",
            "         [-0.0342, -0.1513,  1.1628,  0.3381, -2.4266,  0.3415,  1.1566,\n",
            "          -1.7085,  0.9702, -0.4843,  1.2344,  0.4435],\n",
            "         [ 1.6728, -1.0947,  1.5710,  1.7005,  0.9928, -0.6565, -2.0365,\n",
            "           0.0337, -0.6766, -0.6277, -0.4878,  0.2219],\n",
            "         [ 0.6002, -0.6824, -0.6465, -0.9033,  1.2781, -0.4886,  0.2029,\n",
            "           1.1325,  0.1463,  1.5354,  1.1932,  0.0048],\n",
            "         [-0.2679, -1.1787, -1.6024,  0.3694, -0.9934,  0.5546, -1.2586,\n",
            "           0.5416, -0.2124,  1.5033, -0.4508, -1.9895],\n",
            "         [ 2.5777,  1.7366, -0.9346,  0.2837, -0.8152, -0.3704,  0.2418,\n",
            "           0.0614, -0.3858,  1.4835, -0.0736,  0.4397],\n",
            "         [-0.9950,  0.6258,  0.1800,  2.7300, -1.5928,  0.2763, -0.1658,\n",
            "          -0.4066,  0.4823, -1.3553,  1.1546,  0.8119],\n",
            "         [ 0.8891,  0.1830,  0.3364,  0.3167, -1.1692,  0.3125, -0.2180,\n",
            "          -0.8463,  0.7863,  0.3406,  0.2392,  0.9701],\n",
            "         [ 1.4230, -0.6458,  0.4166, -0.7994,  0.5097, -0.9592, -0.0097,\n",
            "           1.1307, -0.8086,  1.0554,  0.7487, -0.3199],\n",
            "         [-0.7220, -1.6605, -0.6281, -0.1040, -0.0320,  0.0161, -0.5074,\n",
            "          -0.8137,  1.9097,  0.4306, -0.1954,  0.3026],\n",
            "         [-2.1524,  0.5467, -0.5770, -0.3436, -0.2901,  0.3612,  0.2687,\n",
            "           0.4907,  0.1969,  0.1361, -1.1692, -0.3698],\n",
            "         [ 1.3321,  1.4545,  1.2042, -0.7518,  1.1944, -0.1205,  1.7312,\n",
            "           0.9546,  0.9656, -0.1626, -0.7714, -1.0717],\n",
            "         [-1.0636, -1.5432,  0.8644,  0.7235,  1.0843,  0.6996,  0.3332,\n",
            "           0.4722,  0.8526,  1.6692, -0.5927,  0.2859],\n",
            "         [ 1.8412, -0.8743, -0.6029,  0.6285, -0.0621,  1.4313, -1.3213,\n",
            "          -1.2306,  2.3802, -0.1214,  0.2421, -0.7743],\n",
            "         [ 0.1155, -0.8496, -1.7750, -0.5082,  1.1946,  0.8673, -0.8693,\n",
            "          -0.3611, -1.2316, -1.5568, -0.2930,  0.5536],\n",
            "         [-1.2386, -1.6667,  1.3667,  0.0583,  0.5698, -1.3776,  0.0257,\n",
            "          -1.7289, -0.6157,  1.1598, -0.1258, -0.0340],\n",
            "         [ 0.5071, -0.2069, -1.0178, -0.3001, -0.2758, -0.2636,  0.4997,\n",
            "           0.9406,  1.9254,  1.0414, -0.7788, -1.6231],\n",
            "         [ 0.4270,  0.6019, -0.2001,  1.4181, -1.0158, -1.3206, -0.4946,\n",
            "          -0.0628,  0.8524, -0.4882,  1.5627, -0.8923],\n",
            "         [ 0.0709, -0.8275, -1.3215, -2.3887,  1.1954,  0.5870,  1.9099,\n",
            "          -1.2061,  0.5862,  0.2738,  0.1187,  0.2341],\n",
            "         [-0.0572, -0.4580, -0.5840,  1.0584,  1.0001,  0.9362, -0.2172,\n",
            "          -0.3270, -0.2019,  0.1120, -0.1408,  1.1485],\n",
            "         [-0.7865,  1.7298,  0.7637,  0.5961,  0.5916,  1.5370,  2.1159,\n",
            "           0.3139,  1.3594, -0.5067,  0.5330, -0.2075],\n",
            "         [-0.1657, -1.5589,  1.6479,  0.4924,  0.4002,  1.5047,  0.5935,\n",
            "           0.5697, -0.5619, -2.7332, -2.3000,  0.4230],\n",
            "         [ 0.7149, -0.5318,  1.2286,  0.4143,  0.2029, -0.2543, -1.7977,\n",
            "          -0.3891, -0.6786, -0.7187, -1.4711,  0.3230],\n",
            "         [-1.9703,  0.7629, -0.6664,  0.0373,  0.0803,  0.9308,  0.9721,\n",
            "          -0.1900,  0.2211,  1.0069, -3.3744, -2.4978],\n",
            "         [-2.1158, -0.9298, -1.8771, -0.2056,  0.0416, -0.2588, -0.4285,\n",
            "          -0.2747, -0.8066, -0.5296, -0.9084, -1.4104],\n",
            "         [ 0.5844, -0.8491,  0.0968, -1.2683,  0.7822,  1.6793, -0.2503,\n",
            "          -1.4374,  0.3037, -1.7415,  0.1203,  1.8653],\n",
            "         [-0.5816,  1.9501,  0.4225,  1.5358,  0.3444, -0.4358,  0.1380,\n",
            "          -1.5701,  0.0470, -0.8974, -0.7152,  0.8165],\n",
            "         [ 0.6292,  0.3924, -0.9036,  0.1251, -1.0292,  0.8971, -0.5241,\n",
            "          -0.9295, -0.9907, -0.0436, -1.0118,  0.7232]]])\n",
            "Target Tensor:\n",
            " tensor([[[ 0.3351, -1.4842, -0.1436, -0.5985,  0.4548, -0.3830, -0.1436,\n",
            "          -1.1730,  0.3112,  0.1436,  0.4309, -0.0718],\n",
            "         [-0.0239, -0.1436,  1.1730,  0.3351, -2.4178,  0.3351,  1.1491,\n",
            "          -1.6997,  0.9815, -0.4788,  1.2448,  0.4548],\n",
            "         [ 1.6757, -1.1012,  1.5800,  1.6997,  0.9815, -0.6464, -2.0348,\n",
            "           0.0239, -0.6703, -0.6224, -0.4788,  0.2155],\n",
            "         [ 0.5985, -0.6942, -0.6464, -0.9097,  1.2688, -0.4788,  0.1915,\n",
            "           1.1251,  0.1436,  1.5321,  1.1969,  0.0000],\n",
            "         [-0.2633, -1.1730, -1.6039,  0.3591, -0.9815,  0.5506, -1.2688,\n",
            "           0.5506, -0.2155,  1.5082, -0.4548, -1.9869],\n",
            "         [ 2.5854,  1.7475, -0.9336,  0.2873, -0.8139, -0.3591,  0.2394,\n",
            "           0.0718, -0.3830,  1.4842, -0.0718,  0.4309],\n",
            "         [-1.0054,  0.6224,  0.1915,  2.7290, -1.6039,  0.2873, -0.1676,\n",
            "          -0.4070,  0.4788, -1.3645,  1.1491,  0.8139],\n",
            "         [ 0.8857,  0.1915,  0.3351,  0.3112, -1.1730,  0.3112, -0.2155,\n",
            "          -0.8379,  0.7900,  0.3351,  0.2394,  0.9815],\n",
            "         [ 1.4124, -0.6464,  0.4070, -0.7900,  0.5027, -0.9576,  0.0000,\n",
            "           1.1251, -0.8139,  1.0533,  0.7421, -0.3112],\n",
            "         [-0.7182, -1.6518, -0.6224, -0.0958, -0.0239,  0.0239, -0.5027,\n",
            "          -0.8139,  1.9151,  0.4309, -0.1915,  0.3112],\n",
            "         [-2.1545,  0.5506, -0.5745, -0.3351, -0.2873,  0.3591,  0.2633,\n",
            "           0.4788,  0.1915,  0.1436, -1.1730, -0.3591],\n",
            "         [ 1.3406,  1.4603,  1.1969, -0.7421,  1.1969, -0.1197,  1.7236,\n",
            "           0.9576,  0.9576, -0.1676, -0.7660, -1.0773],\n",
            "         [-1.0533, -1.5321,  0.8618,  0.7182,  1.0773,  0.6942,  0.3351,\n",
            "           0.4788,  0.8618,  1.6757, -0.5985,  0.2873],\n",
            "         [ 1.8433, -0.8857, -0.5985,  0.6224, -0.0718,  1.4363, -1.3166,\n",
            "          -1.2209,  2.3700, -0.1197,  0.2394, -0.7660],\n",
            "         [ 0.1197, -0.8379, -1.7715, -0.5027,  1.1969,  0.8618, -0.8618,\n",
            "          -0.3591, -1.2209, -1.5560, -0.2873,  0.5506],\n",
            "         [-1.2448, -1.6757,  1.3645,  0.0479,  0.5745, -1.3885,  0.0239,\n",
            "          -1.7236, -0.6224,  1.1491, -0.1197, -0.0239],\n",
            "         [ 0.5027, -0.2155, -1.0294, -0.3112, -0.2873, -0.2633,  0.5027,\n",
            "           0.9336,  1.9151,  1.0533, -0.7900, -1.6279],\n",
            "         [ 0.4309,  0.5985, -0.1915,  1.4124, -1.0054, -1.3166, -0.5027,\n",
            "          -0.0718,  0.8618, -0.4788,  1.5560, -0.8857],\n",
            "         [ 0.0718, -0.8379, -1.3166, -2.3939,  1.1969,  0.5985,  1.9151,\n",
            "          -1.1969,  0.5745,  0.2633,  0.1197,  0.2394],\n",
            "         [-0.0479, -0.4548, -0.5745,  1.0533,  1.0054,  0.9336, -0.2155,\n",
            "          -0.3351, -0.1915,  0.1197, -0.1436,  1.1491],\n",
            "         [-0.7900,  1.7236,  0.7660,  0.5985,  0.5985,  1.5321,  2.1066,\n",
            "           0.3112,  1.3645, -0.5027,  0.5267, -0.2155],\n",
            "         [-0.1676, -1.5560,  1.6518,  0.5027,  0.4070,  1.5082,  0.5985,\n",
            "           0.5745, -0.5506, -2.7290, -2.2981,  0.4309],\n",
            "         [ 0.7182, -0.5267,  1.2209,  0.4070,  0.1915, -0.2633, -1.7954,\n",
            "          -0.3830, -0.6703, -0.7182, -1.4603,  0.3112],\n",
            "         [-1.9630,  0.7660, -0.6703,  0.0479,  0.0718,  0.9336,  0.9815,\n",
            "          -0.1915,  0.2155,  1.0054, -3.3754, -2.4897],\n",
            "         [-2.1066, -0.9336, -1.8672, -0.2155,  0.0479, -0.2633, -0.4309,\n",
            "          -0.2633, -0.8139, -0.5267, -0.9097, -1.4124],\n",
            "         [ 0.5745, -0.8379,  0.0958, -1.2688,  0.7900,  1.6757, -0.2394,\n",
            "          -1.4363,  0.3112, -1.7475,  0.1197,  1.8672],\n",
            "         [-0.5745,  1.9391,  0.4309,  1.5321,  0.3351, -0.4309,  0.1436,\n",
            "          -1.5800,  0.0479, -0.8857, -0.7182,  0.8139],\n",
            "         [ 0.6224,  0.3830, -0.9097,  0.1197, -1.0294,  0.8857, -0.5267,\n",
            "          -0.9336, -0.9815, -0.0479, -1.0054,  0.7182]]])\n",
            "MSE loss: tensor(4.8882e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Method-2:- Symmetric quantization scheme***"
      ],
      "metadata": {
        "id": "KvhlKOMsLoNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = torch.round(T/s + z)\n",
        "print(f)\n",
        "Tq1 = torch.clip(f, min=-128, max=128) # Here min & max value we can change as per Tbit.\n",
        "# But, I have checked for 8 bit\n",
        "print (Tq1)\n",
        "torch.save(Tq1,'qtz_tensor.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01c8890-810b-45d4-b2fb-38a6d65ed3c2",
        "id": "leoLQZHpL53X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[155.,  79., 135., 116., 160., 125., 135.,  92., 154., 147., 159.,\n",
            "          138.],\n",
            "         [140., 135., 190., 155.,  40., 155., 189.,  70., 182., 121., 193.,\n",
            "          160.],\n",
            "         [211.,  95., 207., 212., 182., 114.,  56., 142., 113., 115., 121.,\n",
            "          150.],\n",
            "         [166., 112., 114., 103., 194., 121., 149., 188., 147., 205., 191.,\n",
            "          141.],\n",
            "         [130.,  92.,  74., 156., 100., 164.,  88., 164., 132., 204., 122.,\n",
            "           58.],\n",
            "         [249., 214., 102., 153., 107., 126., 151., 144., 125., 203., 138.,\n",
            "          159.],\n",
            "         [ 99., 167., 149., 255.,  74., 153., 134., 124., 161.,  84., 189.,\n",
            "          175.],\n",
            "         [178., 149., 155., 154.,  92., 154., 132., 106., 174., 155., 151.,\n",
            "          182.],\n",
            "         [200., 114., 158., 108., 162., 101., 141., 188., 107., 185., 172.,\n",
            "          128.],\n",
            "         [111.,  72., 115., 137., 140., 142., 120., 107., 221., 159., 133.,\n",
            "          154.],\n",
            "         [ 51., 164., 117., 127., 129., 156., 152., 161., 149., 147.,  92.,\n",
            "          126.],\n",
            "         [197., 202., 191., 110., 191., 136., 213., 181., 181., 134., 109.,\n",
            "           96.],\n",
            "         [ 97.,  77., 177., 171., 186., 170., 155., 161., 177., 211., 116.,\n",
            "          153.],\n",
            "         [218., 104., 116., 167., 138., 201.,  86.,  90., 240., 136., 151.,\n",
            "          109.],\n",
            "         [146., 106.,  67., 120., 191., 177., 105., 126.,  90.,  76., 129.,\n",
            "          164.],\n",
            "         [ 89.,  71., 198., 143., 165.,  83., 142.,  69., 115., 189., 136.,\n",
            "          140.],\n",
            "         [162., 132.,  98., 128., 129., 130., 162., 180., 221., 185., 108.,\n",
            "           73.],\n",
            "         [159., 166., 133., 200.,  99.,  86., 120., 138., 177., 121., 206.,\n",
            "          104.],\n",
            "         [144., 106.,  86.,  41., 191., 166., 221.,  91., 165., 152., 146.,\n",
            "          151.],\n",
            "         [139., 122., 117., 185., 183., 180., 132., 127., 133., 146., 135.,\n",
            "          189.],\n",
            "         [108., 213., 173., 166., 166., 205., 229., 154., 198., 120., 163.,\n",
            "          132.],\n",
            "         [134.,  76., 210., 162., 158., 204., 166., 165., 118.,  27.,  45.,\n",
            "          159.],\n",
            "         [171., 119., 192., 158., 149., 130.,  66., 125., 113., 111.,  80.,\n",
            "          154.],\n",
            "         [ 59., 173., 113., 143., 144., 180., 182., 133., 150., 183.,   0.,\n",
            "           37.],\n",
            "         [ 53., 102.,  63., 132., 143., 130., 123., 130., 107., 119., 103.,\n",
            "           82.],\n",
            "         [165., 106., 145.,  88., 174., 211., 131.,  81., 154.,  68., 146.,\n",
            "          219.],\n",
            "         [117., 222., 159., 205., 155., 123., 147.,  75., 143., 104., 111.,\n",
            "          175.],\n",
            "         [167., 157., 103., 146.,  98., 178., 119., 102., 100., 139.,  99.,\n",
            "          171.]]])\n",
            "tensor([[[128.,  79., 128., 116., 128., 125., 128.,  92., 128., 128., 128.,\n",
            "          128.],\n",
            "         [128., 128., 128., 128.,  40., 128., 128.,  70., 128., 121., 128.,\n",
            "          128.],\n",
            "         [128.,  95., 128., 128., 128., 114.,  56., 128., 113., 115., 121.,\n",
            "          128.],\n",
            "         [128., 112., 114., 103., 128., 121., 128., 128., 128., 128., 128.,\n",
            "          128.],\n",
            "         [128.,  92.,  74., 128., 100., 128.,  88., 128., 128., 128., 122.,\n",
            "           58.],\n",
            "         [128., 128., 102., 128., 107., 126., 128., 128., 125., 128., 128.,\n",
            "          128.],\n",
            "         [ 99., 128., 128., 128.,  74., 128., 128., 124., 128.,  84., 128.,\n",
            "          128.],\n",
            "         [128., 128., 128., 128.,  92., 128., 128., 106., 128., 128., 128.,\n",
            "          128.],\n",
            "         [128., 114., 128., 108., 128., 101., 128., 128., 107., 128., 128.,\n",
            "          128.],\n",
            "         [111.,  72., 115., 128., 128., 128., 120., 107., 128., 128., 128.,\n",
            "          128.],\n",
            "         [ 51., 128., 117., 127., 128., 128., 128., 128., 128., 128.,  92.,\n",
            "          126.],\n",
            "         [128., 128., 128., 110., 128., 128., 128., 128., 128., 128., 109.,\n",
            "           96.],\n",
            "         [ 97.,  77., 128., 128., 128., 128., 128., 128., 128., 128., 116.,\n",
            "          128.],\n",
            "         [128., 104., 116., 128., 128., 128.,  86.,  90., 128., 128., 128.,\n",
            "          109.],\n",
            "         [128., 106.,  67., 120., 128., 128., 105., 126.,  90.,  76., 128.,\n",
            "          128.],\n",
            "         [ 89.,  71., 128., 128., 128.,  83., 128.,  69., 115., 128., 128.,\n",
            "          128.],\n",
            "         [128., 128.,  98., 128., 128., 128., 128., 128., 128., 128., 108.,\n",
            "           73.],\n",
            "         [128., 128., 128., 128.,  99.,  86., 120., 128., 128., 121., 128.,\n",
            "          104.],\n",
            "         [128., 106.,  86.,  41., 128., 128., 128.,  91., 128., 128., 128.,\n",
            "          128.],\n",
            "         [128., 122., 117., 128., 128., 128., 128., 127., 128., 128., 128.,\n",
            "          128.],\n",
            "         [108., 128., 128., 128., 128., 128., 128., 128., 128., 120., 128.,\n",
            "          128.],\n",
            "         [128.,  76., 128., 128., 128., 128., 128., 128., 118.,  27.,  45.,\n",
            "          128.],\n",
            "         [128., 119., 128., 128., 128., 128.,  66., 125., 113., 111.,  80.,\n",
            "          128.],\n",
            "         [ 59., 128., 113., 128., 128., 128., 128., 128., 128., 128.,   0.,\n",
            "           37.],\n",
            "         [ 53., 102.,  63., 128., 128., 128., 123., 128., 107., 119., 103.,\n",
            "           82.],\n",
            "         [128., 106., 128.,  88., 128., 128., 128.,  81., 128.,  68., 128.,\n",
            "          128.],\n",
            "         [117., 128., 128., 128., 128., 123., 128.,  75., 128., 104., 111.,\n",
            "          128.],\n",
            "         [128., 128., 103., 128.,  98., 128., 119., 102., 100., 128.,  99.,\n",
            "          128.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tdq1 = s*(Tq1 - z)\n",
        "print(Tdq1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824311c7-bd31-4b0d-820d-96b5a48b872c",
        "id": "t6He4Z7XMGMY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.3112, -1.4842, -0.3112, -0.5985, -0.3112, -0.3830, -0.3112,\n",
            "          -1.1730, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -2.4178, -0.3112, -0.3112,\n",
            "          -1.6997, -0.3112, -0.4788, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.1012, -0.3112, -0.3112, -0.3112, -0.6464, -2.0348,\n",
            "          -0.3112, -0.6703, -0.6224, -0.4788, -0.3112],\n",
            "         [-0.3112, -0.6942, -0.6464, -0.9097, -0.3112, -0.4788, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.1730, -1.6039, -0.3112, -0.9815, -0.3112, -1.2688,\n",
            "          -0.3112, -0.3112, -0.3112, -0.4548, -1.9869],\n",
            "         [-0.3112, -0.3112, -0.9336, -0.3112, -0.8139, -0.3591, -0.3112,\n",
            "          -0.3112, -0.3830, -0.3112, -0.3112, -0.3112],\n",
            "         [-1.0054, -0.3112, -0.3112, -0.3112, -1.6039, -0.3112, -0.3112,\n",
            "          -0.4070, -0.3112, -1.3645, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -1.1730, -0.3112, -0.3112,\n",
            "          -0.8379, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.6464, -0.3112, -0.7900, -0.3112, -0.9576, -0.3112,\n",
            "          -0.3112, -0.8139, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.7182, -1.6518, -0.6224, -0.3112, -0.3112, -0.3112, -0.5027,\n",
            "          -0.8139, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-2.1545, -0.3112, -0.5745, -0.3351, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -1.1730, -0.3591],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.7421, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.7660, -1.0773],\n",
            "         [-1.0533, -1.5321, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.5985, -0.3112],\n",
            "         [-0.3112, -0.8857, -0.5985, -0.3112, -0.3112, -0.3112, -1.3166,\n",
            "          -1.2209, -0.3112, -0.3112, -0.3112, -0.7660],\n",
            "         [-0.3112, -0.8379, -1.7715, -0.5027, -0.3112, -0.3112, -0.8618,\n",
            "          -0.3591, -1.2209, -1.5560, -0.3112, -0.3112],\n",
            "         [-1.2448, -1.6757, -0.3112, -0.3112, -0.3112, -1.3885, -0.3112,\n",
            "          -1.7236, -0.6224, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -1.0294, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.7900, -1.6279],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -1.0054, -1.3166, -0.5027,\n",
            "          -0.3112, -0.3112, -0.4788, -0.3112, -0.8857],\n",
            "         [-0.3112, -0.8379, -1.3166, -2.3939, -0.3112, -0.3112, -0.3112,\n",
            "          -1.1969, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.4548, -0.5745, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3351, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.7900, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.5027, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.5560, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.5506, -2.7290, -2.2981, -0.3112],\n",
            "         [-0.3112, -0.5267, -0.3112, -0.3112, -0.3112, -0.3112, -1.7954,\n",
            "          -0.3830, -0.6703, -0.7182, -1.4603, -0.3112],\n",
            "         [-1.9630, -0.3112, -0.6703, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -3.3754, -2.4897],\n",
            "         [-2.1066, -0.9336, -1.8672, -0.3112, -0.3112, -0.3112, -0.4309,\n",
            "          -0.3112, -0.8139, -0.5267, -0.9097, -1.4124],\n",
            "         [-0.3112, -0.8379, -0.3112, -1.2688, -0.3112, -0.3112, -0.3112,\n",
            "          -1.4363, -0.3112, -1.7475, -0.3112, -0.3112],\n",
            "         [-0.5745, -0.3112, -0.3112, -0.3112, -0.3112, -0.4309, -0.3112,\n",
            "          -1.5800, -0.3112, -0.8857, -0.7182, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.9097, -0.3112, -1.0294, -0.3112, -0.5267,\n",
            "          -0.9336, -0.9815, -0.3112, -1.0054, -0.3112]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# print input and target tensors\n",
        "print(\"Input Tensor:\\n\", T)\n",
        "print(\"Target Tensor:\\n\", Tdq1)\n",
        "# create a criterion to measure the mean absolute error\n",
        "mae = nn.L1Loss()\n",
        "# compute the loss (mean absolute error)\n",
        "output = mae(T, Tdq1)\n",
        "# output.backward()\n",
        "print(\"MAE loss:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc3e9ed-dfd8-4834-8065-34c5a8cfe263",
        "id": "FPJ_lzRVMUcT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor:\n",
            " tensor([[[ 0.3469, -1.4874, -0.1450, -0.6015,  0.4447, -0.3941, -0.1339,\n",
            "          -1.1706,  0.3192,  0.1349,  0.4416, -0.0699],\n",
            "         [-0.0342, -0.1513,  1.1628,  0.3381, -2.4266,  0.3415,  1.1566,\n",
            "          -1.7085,  0.9702, -0.4843,  1.2344,  0.4435],\n",
            "         [ 1.6728, -1.0947,  1.5710,  1.7005,  0.9928, -0.6565, -2.0365,\n",
            "           0.0337, -0.6766, -0.6277, -0.4878,  0.2219],\n",
            "         [ 0.6002, -0.6824, -0.6465, -0.9033,  1.2781, -0.4886,  0.2029,\n",
            "           1.1325,  0.1463,  1.5354,  1.1932,  0.0048],\n",
            "         [-0.2679, -1.1787, -1.6024,  0.3694, -0.9934,  0.5546, -1.2586,\n",
            "           0.5416, -0.2124,  1.5033, -0.4508, -1.9895],\n",
            "         [ 2.5777,  1.7366, -0.9346,  0.2837, -0.8152, -0.3704,  0.2418,\n",
            "           0.0614, -0.3858,  1.4835, -0.0736,  0.4397],\n",
            "         [-0.9950,  0.6258,  0.1800,  2.7300, -1.5928,  0.2763, -0.1658,\n",
            "          -0.4066,  0.4823, -1.3553,  1.1546,  0.8119],\n",
            "         [ 0.8891,  0.1830,  0.3364,  0.3167, -1.1692,  0.3125, -0.2180,\n",
            "          -0.8463,  0.7863,  0.3406,  0.2392,  0.9701],\n",
            "         [ 1.4230, -0.6458,  0.4166, -0.7994,  0.5097, -0.9592, -0.0097,\n",
            "           1.1307, -0.8086,  1.0554,  0.7487, -0.3199],\n",
            "         [-0.7220, -1.6605, -0.6281, -0.1040, -0.0320,  0.0161, -0.5074,\n",
            "          -0.8137,  1.9097,  0.4306, -0.1954,  0.3026],\n",
            "         [-2.1524,  0.5467, -0.5770, -0.3436, -0.2901,  0.3612,  0.2687,\n",
            "           0.4907,  0.1969,  0.1361, -1.1692, -0.3698],\n",
            "         [ 1.3321,  1.4545,  1.2042, -0.7518,  1.1944, -0.1205,  1.7312,\n",
            "           0.9546,  0.9656, -0.1626, -0.7714, -1.0717],\n",
            "         [-1.0636, -1.5432,  0.8644,  0.7235,  1.0843,  0.6996,  0.3332,\n",
            "           0.4722,  0.8526,  1.6692, -0.5927,  0.2859],\n",
            "         [ 1.8412, -0.8743, -0.6029,  0.6285, -0.0621,  1.4313, -1.3213,\n",
            "          -1.2306,  2.3802, -0.1214,  0.2421, -0.7743],\n",
            "         [ 0.1155, -0.8496, -1.7750, -0.5082,  1.1946,  0.8673, -0.8693,\n",
            "          -0.3611, -1.2316, -1.5568, -0.2930,  0.5536],\n",
            "         [-1.2386, -1.6667,  1.3667,  0.0583,  0.5698, -1.3776,  0.0257,\n",
            "          -1.7289, -0.6157,  1.1598, -0.1258, -0.0340],\n",
            "         [ 0.5071, -0.2069, -1.0178, -0.3001, -0.2758, -0.2636,  0.4997,\n",
            "           0.9406,  1.9254,  1.0414, -0.7788, -1.6231],\n",
            "         [ 0.4270,  0.6019, -0.2001,  1.4181, -1.0158, -1.3206, -0.4946,\n",
            "          -0.0628,  0.8524, -0.4882,  1.5627, -0.8923],\n",
            "         [ 0.0709, -0.8275, -1.3215, -2.3887,  1.1954,  0.5870,  1.9099,\n",
            "          -1.2061,  0.5862,  0.2738,  0.1187,  0.2341],\n",
            "         [-0.0572, -0.4580, -0.5840,  1.0584,  1.0001,  0.9362, -0.2172,\n",
            "          -0.3270, -0.2019,  0.1120, -0.1408,  1.1485],\n",
            "         [-0.7865,  1.7298,  0.7637,  0.5961,  0.5916,  1.5370,  2.1159,\n",
            "           0.3139,  1.3594, -0.5067,  0.5330, -0.2075],\n",
            "         [-0.1657, -1.5589,  1.6479,  0.4924,  0.4002,  1.5047,  0.5935,\n",
            "           0.5697, -0.5619, -2.7332, -2.3000,  0.4230],\n",
            "         [ 0.7149, -0.5318,  1.2286,  0.4143,  0.2029, -0.2543, -1.7977,\n",
            "          -0.3891, -0.6786, -0.7187, -1.4711,  0.3230],\n",
            "         [-1.9703,  0.7629, -0.6664,  0.0373,  0.0803,  0.9308,  0.9721,\n",
            "          -0.1900,  0.2211,  1.0069, -3.3744, -2.4978],\n",
            "         [-2.1158, -0.9298, -1.8771, -0.2056,  0.0416, -0.2588, -0.4285,\n",
            "          -0.2747, -0.8066, -0.5296, -0.9084, -1.4104],\n",
            "         [ 0.5844, -0.8491,  0.0968, -1.2683,  0.7822,  1.6793, -0.2503,\n",
            "          -1.4374,  0.3037, -1.7415,  0.1203,  1.8653],\n",
            "         [-0.5816,  1.9501,  0.4225,  1.5358,  0.3444, -0.4358,  0.1380,\n",
            "          -1.5701,  0.0470, -0.8974, -0.7152,  0.8165],\n",
            "         [ 0.6292,  0.3924, -0.9036,  0.1251, -1.0292,  0.8971, -0.5241,\n",
            "          -0.9295, -0.9907, -0.0436, -1.0118,  0.7232]]])\n",
            "Target Tensor:\n",
            " tensor([[[-0.3112, -1.4842, -0.3112, -0.5985, -0.3112, -0.3830, -0.3112,\n",
            "          -1.1730, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -2.4178, -0.3112, -0.3112,\n",
            "          -1.6997, -0.3112, -0.4788, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.1012, -0.3112, -0.3112, -0.3112, -0.6464, -2.0348,\n",
            "          -0.3112, -0.6703, -0.6224, -0.4788, -0.3112],\n",
            "         [-0.3112, -0.6942, -0.6464, -0.9097, -0.3112, -0.4788, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.1730, -1.6039, -0.3112, -0.9815, -0.3112, -1.2688,\n",
            "          -0.3112, -0.3112, -0.3112, -0.4548, -1.9869],\n",
            "         [-0.3112, -0.3112, -0.9336, -0.3112, -0.8139, -0.3591, -0.3112,\n",
            "          -0.3112, -0.3830, -0.3112, -0.3112, -0.3112],\n",
            "         [-1.0054, -0.3112, -0.3112, -0.3112, -1.6039, -0.3112, -0.3112,\n",
            "          -0.4070, -0.3112, -1.3645, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -1.1730, -0.3112, -0.3112,\n",
            "          -0.8379, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.6464, -0.3112, -0.7900, -0.3112, -0.9576, -0.3112,\n",
            "          -0.3112, -0.8139, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.7182, -1.6518, -0.6224, -0.3112, -0.3112, -0.3112, -0.5027,\n",
            "          -0.8139, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-2.1545, -0.3112, -0.5745, -0.3351, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -1.1730, -0.3591],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.7421, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.7660, -1.0773],\n",
            "         [-1.0533, -1.5321, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.5985, -0.3112],\n",
            "         [-0.3112, -0.8857, -0.5985, -0.3112, -0.3112, -0.3112, -1.3166,\n",
            "          -1.2209, -0.3112, -0.3112, -0.3112, -0.7660],\n",
            "         [-0.3112, -0.8379, -1.7715, -0.5027, -0.3112, -0.3112, -0.8618,\n",
            "          -0.3591, -1.2209, -1.5560, -0.3112, -0.3112],\n",
            "         [-1.2448, -1.6757, -0.3112, -0.3112, -0.3112, -1.3885, -0.3112,\n",
            "          -1.7236, -0.6224, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -1.0294, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.7900, -1.6279],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -1.0054, -1.3166, -0.5027,\n",
            "          -0.3112, -0.3112, -0.4788, -0.3112, -0.8857],\n",
            "         [-0.3112, -0.8379, -1.3166, -2.3939, -0.3112, -0.3112, -0.3112,\n",
            "          -1.1969, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.4548, -0.5745, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3351, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.7900, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.5027, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.5560, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.5506, -2.7290, -2.2981, -0.3112],\n",
            "         [-0.3112, -0.5267, -0.3112, -0.3112, -0.3112, -0.3112, -1.7954,\n",
            "          -0.3830, -0.6703, -0.7182, -1.4603, -0.3112],\n",
            "         [-1.9630, -0.3112, -0.6703, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -3.3754, -2.4897],\n",
            "         [-2.1066, -0.9336, -1.8672, -0.3112, -0.3112, -0.3112, -0.4309,\n",
            "          -0.3112, -0.8139, -0.5267, -0.9097, -1.4124],\n",
            "         [-0.3112, -0.8379, -0.3112, -1.2688, -0.3112, -0.3112, -0.3112,\n",
            "          -1.4363, -0.3112, -1.7475, -0.3112, -0.3112],\n",
            "         [-0.5745, -0.3112, -0.3112, -0.3112, -0.3112, -0.4309, -0.3112,\n",
            "          -1.5800, -0.3112, -0.8857, -0.7182, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.9097, -0.3112, -1.0294, -0.3112, -0.5267,\n",
            "          -0.9336, -0.9815, -0.3112, -1.0054, -0.3112]]])\n",
            "MAE loss: tensor(0.5728)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# print input and target tensors\n",
        "print(\"Input Tensor:\\n\", T)\n",
        "print(\"Target Tensor:\\n\", Tdq1)\n",
        "\n",
        "# create a criterion to measure the mean squared error\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "# compute the loss (mean squared error)\n",
        "output = mse(T, Tdq1)\n",
        "\n",
        "# output.backward()\n",
        "print(\"MSE loss:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d819c2f-740e-406c-9f1b-7270b5ac35ed",
        "id": "Vkpv5bdvMcDC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor:\n",
            " tensor([[[ 0.3469, -1.4874, -0.1450, -0.6015,  0.4447, -0.3941, -0.1339,\n",
            "          -1.1706,  0.3192,  0.1349,  0.4416, -0.0699],\n",
            "         [-0.0342, -0.1513,  1.1628,  0.3381, -2.4266,  0.3415,  1.1566,\n",
            "          -1.7085,  0.9702, -0.4843,  1.2344,  0.4435],\n",
            "         [ 1.6728, -1.0947,  1.5710,  1.7005,  0.9928, -0.6565, -2.0365,\n",
            "           0.0337, -0.6766, -0.6277, -0.4878,  0.2219],\n",
            "         [ 0.6002, -0.6824, -0.6465, -0.9033,  1.2781, -0.4886,  0.2029,\n",
            "           1.1325,  0.1463,  1.5354,  1.1932,  0.0048],\n",
            "         [-0.2679, -1.1787, -1.6024,  0.3694, -0.9934,  0.5546, -1.2586,\n",
            "           0.5416, -0.2124,  1.5033, -0.4508, -1.9895],\n",
            "         [ 2.5777,  1.7366, -0.9346,  0.2837, -0.8152, -0.3704,  0.2418,\n",
            "           0.0614, -0.3858,  1.4835, -0.0736,  0.4397],\n",
            "         [-0.9950,  0.6258,  0.1800,  2.7300, -1.5928,  0.2763, -0.1658,\n",
            "          -0.4066,  0.4823, -1.3553,  1.1546,  0.8119],\n",
            "         [ 0.8891,  0.1830,  0.3364,  0.3167, -1.1692,  0.3125, -0.2180,\n",
            "          -0.8463,  0.7863,  0.3406,  0.2392,  0.9701],\n",
            "         [ 1.4230, -0.6458,  0.4166, -0.7994,  0.5097, -0.9592, -0.0097,\n",
            "           1.1307, -0.8086,  1.0554,  0.7487, -0.3199],\n",
            "         [-0.7220, -1.6605, -0.6281, -0.1040, -0.0320,  0.0161, -0.5074,\n",
            "          -0.8137,  1.9097,  0.4306, -0.1954,  0.3026],\n",
            "         [-2.1524,  0.5467, -0.5770, -0.3436, -0.2901,  0.3612,  0.2687,\n",
            "           0.4907,  0.1969,  0.1361, -1.1692, -0.3698],\n",
            "         [ 1.3321,  1.4545,  1.2042, -0.7518,  1.1944, -0.1205,  1.7312,\n",
            "           0.9546,  0.9656, -0.1626, -0.7714, -1.0717],\n",
            "         [-1.0636, -1.5432,  0.8644,  0.7235,  1.0843,  0.6996,  0.3332,\n",
            "           0.4722,  0.8526,  1.6692, -0.5927,  0.2859],\n",
            "         [ 1.8412, -0.8743, -0.6029,  0.6285, -0.0621,  1.4313, -1.3213,\n",
            "          -1.2306,  2.3802, -0.1214,  0.2421, -0.7743],\n",
            "         [ 0.1155, -0.8496, -1.7750, -0.5082,  1.1946,  0.8673, -0.8693,\n",
            "          -0.3611, -1.2316, -1.5568, -0.2930,  0.5536],\n",
            "         [-1.2386, -1.6667,  1.3667,  0.0583,  0.5698, -1.3776,  0.0257,\n",
            "          -1.7289, -0.6157,  1.1598, -0.1258, -0.0340],\n",
            "         [ 0.5071, -0.2069, -1.0178, -0.3001, -0.2758, -0.2636,  0.4997,\n",
            "           0.9406,  1.9254,  1.0414, -0.7788, -1.6231],\n",
            "         [ 0.4270,  0.6019, -0.2001,  1.4181, -1.0158, -1.3206, -0.4946,\n",
            "          -0.0628,  0.8524, -0.4882,  1.5627, -0.8923],\n",
            "         [ 0.0709, -0.8275, -1.3215, -2.3887,  1.1954,  0.5870,  1.9099,\n",
            "          -1.2061,  0.5862,  0.2738,  0.1187,  0.2341],\n",
            "         [-0.0572, -0.4580, -0.5840,  1.0584,  1.0001,  0.9362, -0.2172,\n",
            "          -0.3270, -0.2019,  0.1120, -0.1408,  1.1485],\n",
            "         [-0.7865,  1.7298,  0.7637,  0.5961,  0.5916,  1.5370,  2.1159,\n",
            "           0.3139,  1.3594, -0.5067,  0.5330, -0.2075],\n",
            "         [-0.1657, -1.5589,  1.6479,  0.4924,  0.4002,  1.5047,  0.5935,\n",
            "           0.5697, -0.5619, -2.7332, -2.3000,  0.4230],\n",
            "         [ 0.7149, -0.5318,  1.2286,  0.4143,  0.2029, -0.2543, -1.7977,\n",
            "          -0.3891, -0.6786, -0.7187, -1.4711,  0.3230],\n",
            "         [-1.9703,  0.7629, -0.6664,  0.0373,  0.0803,  0.9308,  0.9721,\n",
            "          -0.1900,  0.2211,  1.0069, -3.3744, -2.4978],\n",
            "         [-2.1158, -0.9298, -1.8771, -0.2056,  0.0416, -0.2588, -0.4285,\n",
            "          -0.2747, -0.8066, -0.5296, -0.9084, -1.4104],\n",
            "         [ 0.5844, -0.8491,  0.0968, -1.2683,  0.7822,  1.6793, -0.2503,\n",
            "          -1.4374,  0.3037, -1.7415,  0.1203,  1.8653],\n",
            "         [-0.5816,  1.9501,  0.4225,  1.5358,  0.3444, -0.4358,  0.1380,\n",
            "          -1.5701,  0.0470, -0.8974, -0.7152,  0.8165],\n",
            "         [ 0.6292,  0.3924, -0.9036,  0.1251, -1.0292,  0.8971, -0.5241,\n",
            "          -0.9295, -0.9907, -0.0436, -1.0118,  0.7232]]])\n",
            "Target Tensor:\n",
            " tensor([[[-0.3112, -1.4842, -0.3112, -0.5985, -0.3112, -0.3830, -0.3112,\n",
            "          -1.1730, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -2.4178, -0.3112, -0.3112,\n",
            "          -1.6997, -0.3112, -0.4788, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.1012, -0.3112, -0.3112, -0.3112, -0.6464, -2.0348,\n",
            "          -0.3112, -0.6703, -0.6224, -0.4788, -0.3112],\n",
            "         [-0.3112, -0.6942, -0.6464, -0.9097, -0.3112, -0.4788, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.1730, -1.6039, -0.3112, -0.9815, -0.3112, -1.2688,\n",
            "          -0.3112, -0.3112, -0.3112, -0.4548, -1.9869],\n",
            "         [-0.3112, -0.3112, -0.9336, -0.3112, -0.8139, -0.3591, -0.3112,\n",
            "          -0.3112, -0.3830, -0.3112, -0.3112, -0.3112],\n",
            "         [-1.0054, -0.3112, -0.3112, -0.3112, -1.6039, -0.3112, -0.3112,\n",
            "          -0.4070, -0.3112, -1.3645, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -1.1730, -0.3112, -0.3112,\n",
            "          -0.8379, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.6464, -0.3112, -0.7900, -0.3112, -0.9576, -0.3112,\n",
            "          -0.3112, -0.8139, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.7182, -1.6518, -0.6224, -0.3112, -0.3112, -0.3112, -0.5027,\n",
            "          -0.8139, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-2.1545, -0.3112, -0.5745, -0.3351, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -1.1730, -0.3591],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.7421, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.7660, -1.0773],\n",
            "         [-1.0533, -1.5321, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.5985, -0.3112],\n",
            "         [-0.3112, -0.8857, -0.5985, -0.3112, -0.3112, -0.3112, -1.3166,\n",
            "          -1.2209, -0.3112, -0.3112, -0.3112, -0.7660],\n",
            "         [-0.3112, -0.8379, -1.7715, -0.5027, -0.3112, -0.3112, -0.8618,\n",
            "          -0.3591, -1.2209, -1.5560, -0.3112, -0.3112],\n",
            "         [-1.2448, -1.6757, -0.3112, -0.3112, -0.3112, -1.3885, -0.3112,\n",
            "          -1.7236, -0.6224, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.3112, -1.0294, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -0.7900, -1.6279],\n",
            "         [-0.3112, -0.3112, -0.3112, -0.3112, -1.0054, -1.3166, -0.5027,\n",
            "          -0.3112, -0.3112, -0.4788, -0.3112, -0.8857],\n",
            "         [-0.3112, -0.8379, -1.3166, -2.3939, -0.3112, -0.3112, -0.3112,\n",
            "          -1.1969, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.3112, -0.4548, -0.5745, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3351, -0.3112, -0.3112, -0.3112, -0.3112],\n",
            "         [-0.7900, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.5027, -0.3112, -0.3112],\n",
            "         [-0.3112, -1.5560, -0.3112, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.5506, -2.7290, -2.2981, -0.3112],\n",
            "         [-0.3112, -0.5267, -0.3112, -0.3112, -0.3112, -0.3112, -1.7954,\n",
            "          -0.3830, -0.6703, -0.7182, -1.4603, -0.3112],\n",
            "         [-1.9630, -0.3112, -0.6703, -0.3112, -0.3112, -0.3112, -0.3112,\n",
            "          -0.3112, -0.3112, -0.3112, -3.3754, -2.4897],\n",
            "         [-2.1066, -0.9336, -1.8672, -0.3112, -0.3112, -0.3112, -0.4309,\n",
            "          -0.3112, -0.8139, -0.5267, -0.9097, -1.4124],\n",
            "         [-0.3112, -0.8379, -0.3112, -1.2688, -0.3112, -0.3112, -0.3112,\n",
            "          -1.4363, -0.3112, -1.7475, -0.3112, -0.3112],\n",
            "         [-0.5745, -0.3112, -0.3112, -0.3112, -0.3112, -0.4309, -0.3112,\n",
            "          -1.5800, -0.3112, -0.8857, -0.7182, -0.3112],\n",
            "         [-0.3112, -0.3112, -0.9097, -0.3112, -1.0294, -0.3112, -0.5267,\n",
            "          -0.9336, -0.9815, -0.3112, -1.0054, -0.3112]]])\n",
            "MSE loss: tensor(0.7774)\n"
          ]
        }
      ]
    }
  ]
}